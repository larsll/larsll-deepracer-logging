# Deepracer Logging Analysis

This repository contains scripts for analyzing and combining video files generated by AWS Deepracer. Below is a brief overview of the scripts and their command-line parameters.

## Scripts

### 1. `bag_analysis_batch.sh`

This script processes multiple ROS bag files in a specified directory using a Python analysis script.

#### Usage

```shell
./bag_analysis_batch.sh -d <directory> -m <models_directory>
```

#### Parameters

- `-d <directory>`: The directory containing the ROS bag files.
- `-m <models_directory>`: The directory containing the model files.

### 2. `bag_analysis.py`

This script analyzes a single ROS bag file and generates a video with annotated frames.

#### Usage

```shell
python3 bag_analysis.py --bag_path <bag_path> --model_path <model_path> [options]
```

#### Parameters

- `--codec`: The codec for the video writer (default: `avc1`).
- `--bag_path`: The path to the ROS bag file (required).
- `--model_path`: The path to the model directory (required).
- `--frame_limit`: Max number of frames to process (default: `None`).
- `--describe`: Describe the actions (default: `False`).
- `--relative_labels`: Make labels relative, not fixed to value in action space (default: `False`).
- `--background`: Add a background to the video (default: `True`).

### 3. `combine_videos.py`

This script combines multiple video files into a single video file, adding divider frames with metadata between each video.

#### Usage

```shell
python3 combine_videos.py --directory <directory> --output_dir <output_dir> [options]
```

#### Parameters

- `--codec`: The codec for the video writer (default: `avc1`).
- `--directory`: The directory containing the video files (required).
- `--output_dir`: The directory to save the combined videos (required).
- `--background`: The path to the background image for dividers (default: `resources/AWS-Deepracer_Background_Machine-Learning.jpg`).
- `--pattern`: Pattern to filter video files (default: `*.mp4`).

## Running with Docker

To simplify the setup and ensure all dependencies are met, you can use Docker to build and run the scripts in an environment where ROS and TensorFlow are installed.

### Building the Docker Image

First, build the Docker image using the provided `Dockerfile`.

```shell
docker buildx build -t local/deepracer-analysis:ros-tf -f Dockerfile .
```

### Running the Docker Container

Once the image is built, you can run the container and execute the scripts inside it.

```shell
docker run -ti -p 8888:8888 -v `pwd`:/workspace/analysis -v /path/to/logs:/workspace/logs -v /path/to/models:/workspace/models local/deepracer-analysis:ros-tf <script> <parameters>
```

Replace `<script>` with the script you want to run (e.g., `bag_analysis_batch.sh`, `bag_analysis.py`, `combine_videos.py`) and `<parameters>` with the appropriate parameters for the script.

### Example

To analyze ROS bag files and combine the resulting videos using Docker:

1. Run `bag_analysis_batch.sh` inside the Docker container:
    ```shell
    docker run -ti -p 8888:8888 -v `pwd`:/workspace/analysis -v /path/to/bag/files:/workspace/logs -v /path/to/models:/workspace/models local/deepracer-analysis:ros-tf ./bag_analysis_batch.sh -d /workspace/logs -m /workspace/models
    ```

2. Run `combine_videos.py` inside the Docker container:
    ```shell
    docker run -ti -p 8888:8888 -v `pwd`:/workspace/analysis -v /path/to/videos:/workspace/logs -v /path/to/output:/workspace/models local/deepracer-analysis:ros-tf python3 combine_videos.py --directory /workspace/logs --output_dir /workspace/models
    ```

This will process the ROS bag files and combine the generated videos with metadata dividers in the specified output directory.

## Resources

The scripts use custom fonts and background images located in the `resources` directory. Ensure these resources are available in the specified paths.

- `Amazon_Ember_Bd.ttf`
- `Amazon_Ember_Rg.ttf`
- `AWS-Deepracer_Background_Machine-Learning.jpg`

## Example

To process ROS bag files and combine the resulting videos:

1. Run `bag_analysis_batch.sh` to analyze the bag files:
    ```shell
    ./bag_analysis_batch.sh -d /path/to/bag/files -m /path/to/models
    ```

2. Run `combine_videos.py` to combine the generated videos:
    ```shell
    python3 combine_videos.py --directory /path/to/videos --output_dir /path/to/output
    ```

This will generate combined videos with metadata dividers in the specified output directory.
