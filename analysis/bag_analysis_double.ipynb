{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import rosbag2_py\n",
    "import datetime\n",
    "import json\n",
    "from io import BytesIO\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib import gridspec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from cv_bridge import CvBridge\n",
    "bridge = CvBridge()\n",
    "\n",
    "from sensor_msgs.msg import Image\n",
    "from deepracer_interfaces_pkg.msg import InferResultsArray, InferResults\n",
    "from rclpy.serialization import deserialize_message\n",
    "\n",
    "from deepracer_viz.gradcam.cam import GradCam\n",
    "from deepracer_viz.model.model import Model\n",
    "from deepracer_viz.model.metadata import ModelMetadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rosbag_options(path, serialization_format='cdr'):\n",
    "    storage_options = rosbag2_py.StorageOptions(uri=path, storage_id='sqlite3')\n",
    "\n",
    "    converter_options = rosbag2_py.ConverterOptions(\n",
    "        input_serialization_format=serialization_format,\n",
    "        output_serialization_format=serialization_format)\n",
    "\n",
    "    return storage_options, converter_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(action_names, height, width, dpi):\n",
    "   \n",
    "    fig = plt.figure(figsize=(width/dpi,height/dpi), dpi=dpi)\n",
    "    x = list(range(0,len(action_names)))\n",
    "\n",
    "    spec = gridspec.GridSpec(ncols=3, nrows=2,\n",
    "                            width_ratios=[1, 1, 1], wspace=0.1,\n",
    "                            hspace=0.1, height_ratios=[3, 1], left=0.05,right=0.95,top=0.99,bottom=0.2)\n",
    "    ax00 = fig.add_subplot(spec[0])\n",
    "    plt.setp(ax00, xlabel=\"Original\")\n",
    "    plt.tick_params(labelleft = False, labelbottom=False)\n",
    "\n",
    "    ax01 = fig.add_subplot(spec[1])\n",
    "    plt.setp(ax01, xlabel=\"GradCam\")\n",
    "    plt.tick_params(labelleft = False, labelbottom=False)\n",
    "\n",
    "    ax02 = fig.add_subplot(spec[2])\n",
    "    plt.setp(ax02, xlabel=\"GradCam-Edit\")\n",
    "    plt.tick_params(labelleft = False, labelbottom=False)\n",
    "\n",
    "    ax10 = fig.add_subplot(spec[3])\n",
    "    ax10.set_ylim(0.0, 1.0)\n",
    "    plt.setp(ax10, xlabel=\"OpenVINO\")\n",
    "    plt.xticks(x,action_names[::-1],rotation='vertical')\n",
    "\n",
    "    ax11 = fig.add_subplot(spec[4], sharey=ax10)\n",
    "    ax11.set_ylim(0.0, 1.0)\n",
    "    plt.setp(ax11, xlabel=\"Tensorflow\")\n",
    "    plt.xticks(x,action_names[::-1],rotation='vertical')\n",
    "\n",
    "    ax12 = fig.add_subplot(spec[5], sharey=ax10)\n",
    "    ax12.set_ylim(0.0, 1.0)\n",
    "    plt.setp(ax12, xlabel=\"Tensorflow-Edit\")\n",
    "    plt.xticks(x,action_names[::-1],rotation='vertical')\n",
    "\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_plot(fig: Figure, step, action_names, img, gradcam, gradcam2):\n",
    "\n",
    "    x = list(range(0,len(action_names)))\n",
    "\n",
    "    openvino_result = pd.DataFrame(step['openvino_results'])\n",
    "    tf_result = pd.DataFrame(step['tf_results'])\n",
    "    tf_result_2 = pd.DataFrame(step['tf_results_2'])\n",
    "\n",
    "    ax = fig.get_axes()\n",
    "\n",
    "    for a in ax:\n",
    "        for p in set(a.containers):\n",
    "            p.remove()\n",
    "        for i in set(a.images):\n",
    "            i.remove()\n",
    "\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(gradcam)\n",
    "    ax[2].imshow(gradcam2)\n",
    "    ax[3].bar(x,openvino_result['probability'][::-1], color='blue')\n",
    "    ax[4].bar(x,tf_result['probability'][::-1], color='blue')\n",
    "    ax[5].bar(x,tf_result_2['probability'][::-1], color='blue')\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    buf = fig.canvas.buffer_rgba()\n",
    "    ncols, nrows = fig.canvas.get_width_height()\n",
    "    return cv2.cvtColor(np.frombuffer(buf, dtype=np.uint8).reshape(nrows, ncols, 4), cv2.COLOR_RGBA2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_values(gradient_img, multiplier=1):\n",
    "    \"\"\" Given the image gradient returns gradient_alpha_rgb_mul and one_minus_gradient_alpha.\n",
    "    These pre-calculated numbers are used to apply the gradient on the camera image\n",
    "\n",
    "    Arguments:\n",
    "        gradient_img (Image): Gradient image that has to applied on the camera image\n",
    "        multiplier (float): This decides what percentage of gradient images alpha has to be applied.\n",
    "                            This is useful in fading feature.\n",
    "\n",
    "    Returns:\n",
    "        (tuple): gradient_alpha_rgb_mul (Numpy.Array) gradient_img * gradient_alpha value\n",
    "                 one_minus_gradient_alpha (Numpy.Array) (1 - gradient_alpha)\n",
    "    \"\"\"\n",
    "    (height, width, _) = gradient_img.shape\n",
    "    gradient_alpha = (gradient_img[:, :, 3] / 255.0 * multiplier).reshape(height, width, 1)\n",
    "\n",
    "    gradient_alpha_rgb_mul = gradient_img * gradient_alpha\n",
    "    one_minus_gradient_alpha = (1 - gradient_alpha).reshape(height, width)\n",
    "    return gradient_alpha_rgb_mul, one_minus_gradient_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradient(main_image, gradient_alpha_rgb_mul, one_minus_gradient_alpha):\n",
    "    \"\"\" The gradient on the image is overlayed so that text looks visible and clear.\n",
    "    This leaves a good effect on the image.\n",
    "    The older code took 6.348s for 1000 runs\n",
    "\n",
    "    Numpy broadcasting is slower than normal python\n",
    "    major_cv_image_1[:, :, :4] = (gradient_alpha_rgb_mul + (major_cv_image_1 * one_minus_gradient_alpha))[:, :, :4]\n",
    "    Timeit 1000 runs - 6.523s\n",
    "\n",
    "    The current code takes - 5.131s for 1000 runs\n",
    "\n",
    "    Args:\n",
    "        main_image (Image): The main image where gradient has to be applied\n",
    "        gradient_alpha_rgb_mul (Numpy.Array): gradient_img * gradient_alpha value\n",
    "        one_minus_gradient_alpha (Numpy.Array): (1 - gradient_alpha)\n",
    "    Returns:\n",
    "        Image: Gradient applied image\n",
    "    \"\"\"\n",
    "    for channel in range(0, 4):\n",
    "        main_image[:, :, channel] = gradient_alpha_rgb_mul[:, :, channel] + \\\n",
    "            (main_image[:, :, channel] * one_minus_gradient_alpha)\n",
    "    return main_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path, img_size=None):\n",
    "    \"\"\" Given the icon_name in the track_iconography folder without png, gives back cv2 image\n",
    "    with all 4 channels\n",
    "    Args:\n",
    "        icon_name (str): The name of the icon in the track_iconography folder\n",
    "        img_size (tuple): If you want to resize the image (width, height) (default: {None})\n",
    "    Returns:\n",
    "        Image: The cv2 image read from the .png file\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGBA)\n",
    "    if img_size:\n",
    "        image = cv2.resize(image, img_size)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bag_path = '/workspace/logs/deepracer-bag-20221201-155319'\n",
    "metadata_json = '/workspace/logs/model/model_metadata.json'\n",
    "model_pb = '/workspace/logs/model/model.pb'\n",
    "overlay_img = '/workspace/analysis/resources/fade_gray_overlay.png'\n",
    "CODEC = \"avc1\"\n",
    "output_file = \"/workspace/logs/test.mp4\"\n",
    "width = 1350\n",
    "height = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_img = get_image(overlay_img)\n",
    "gradient_img = cv2.cvtColor(gradient_img, cv2.COLOR_RGBA2BGRA)\n",
    "gradient_alpha_rgb_mul, one_minus_gradient_alpha = get_gradient_values(gradient_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1675198180.606949726] [rosbag2_storage]: Opened database '/workspace/logs/deepracer-bag-20221201-155319/deepracer-bag-20221201-155319_0.db3' for READ_ONLY.\n"
     ]
    }
   ],
   "source": [
    "storage_options, converter_options = get_rosbag_options(bag_path)\n",
    "\n",
    "reader = rosbag2_py.SequentialReader()\n",
    "reader.open(storage_options, converter_options)\n",
    "storage_filter = rosbag2_py.StorageFilter(topics=['/inference_pkg/rl_results'])\n",
    "\n",
    "metadata = ModelMetadata.from_file(metadata_json)\n",
    "model = Model.from_file(model_pb_path=model_pb, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2022-12-01 20:53:19.335952\n",
      "Loaded 15 steps from 15.\n",
      "Duration: 0.47 seconds\n",
      "Average FPS: 30.0\n",
      "Action Space: 11 actions\n",
      "Input image: 640x480, 3 channels.\n",
      "Total messages: 4521\n"
     ]
    }
   ],
   "source": [
    "reader.set_filter(storage_filter)\n",
    "\n",
    "first_stamp = -1\n",
    "steps_data = {'steps': []}\n",
    "\n",
    "s = 0\n",
    "\n",
    "while reader.has_next() and s < 15:\n",
    "    step = {}\n",
    "    \n",
    "    (topic, data, t) = reader.read_next()\n",
    "    msg = deserialize_message(data, InferResultsArray)\n",
    "\n",
    "    # Timestamp\n",
    "    timestamp: float = (msg.images[0].header.stamp.sec + msg.images[0].header.stamp.nanosec / 1e9)\n",
    "\n",
    "    if first_stamp == -1:\n",
    "        first_stamp = timestamp\n",
    "        timestamp = 0\n",
    "    else:\n",
    "        timestamp = timestamp - first_stamp\n",
    "\n",
    "    step['timestamp'] = timestamp\n",
    "    step['seq'] = int(msg.images[0].header.frame_id)\n",
    "\n",
    "    s += 1\n",
    "    steps_data['steps'].append(step)\n",
    "\n",
    "while reader.has_next():\n",
    "    (topic, data, t) = reader.read_next()\n",
    "    s += 1\n",
    "    \n",
    "df = pd.json_normalize(steps_data['steps'])\n",
    "del steps_data\n",
    "\n",
    "step_diff = df['seq'].max() - df['seq'].min()\n",
    "fps = step_diff / df['timestamp'].max()\n",
    "tmp_img = bridge.compressed_imgmsg_to_cv2(msg.images[0], desired_encoding=\"passthrough\")\n",
    "\n",
    "print(\"Start time: {}\".format(datetime.datetime.fromtimestamp(first_stamp)))\n",
    "print(\"Loaded {} steps from {}.\".format(len(df.index), step_diff + 1))\n",
    "print(\"Duration: {:.2f} seconds\".format(df['timestamp'].max()))\n",
    "print(\"Average FPS: {:.1f}\".format(fps))\n",
    "print(\"Action Space: {} actions\".format(len(msg.results)))\n",
    "print(\"Input image: {}x{}, {} channels.\".format(tmp_img.shape[1], tmp_img.shape[0], tmp_img.shape[2]))\n",
    "print(\"Total messages: {}\".format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1675198181.976651466] [rosbag2_storage]: Opened database '/workspace/logs/deepracer-bag-20221201-155319/deepracer-bag-20221201-155319_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cbd504bdb244e7861324c390606e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4521 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost/replica:0/task:0/device:CPU:0\n",
      "one_hot/indices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "one_hot/depth: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Sum/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/grad_ys_0/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/Size: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/range/start: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/range/delta: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/ones/Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/policy_grad/Sum/reduction_indices: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/strided_slice_grad/StridedSliceGrad/begin: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/strided_slice_grad/StridedSliceGrad/end: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/strided_slice_grad/StridedSliceGrad/strides: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/truediv: (RealDiv): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_0/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_0/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_0/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_0/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/BatchnormActivationDropout_1_activation: (Relu): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_2/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_2/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_2/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_2/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/BatchnormActivationDropout_3_activation: (Relu): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_4/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_4/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_4/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_4/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/BatchnormActivationDropout_5_activation: (Relu): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Flatten/flatten/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/middleware_fc_embedder/Dense_0/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/middleware_fc_embedder/Dense_0/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/middleware_fc_embedder/Dense_0/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/middleware_fc_embedder/Dense_0/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/middleware_fc_embedder/BatchnormActivationDropout_1_activation: (Relu): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/gradients_from_head_0-0_rescalers/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/StopGradient/input: (Pack): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/StopGradient: (StopGradient): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/mul_1/y: (Pack): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/add: (AddV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/ppo_head_0/strided_slice: (StridedSlice): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/ppo_head_0/policy_fc/kernel/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/ppo_head_0/policy_fc/bias/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/ppo_head_0/policy_fc/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/ppo_head_0/policy_fc/BiasAdd: (BiasAdd): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/ppo_head_0/policy: (Softmax): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "one_hot: (OneHot): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Shape: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/grad_ys_0: (Fill): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/add: (AddV2): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/mod: (FloorMod): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/range: (Range): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/ones: (Fill): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/DynamicStitch: (DynamicStitch): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Sum_grad/BroadcastTo: (BroadcastTo): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Mul_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Mul_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Mul_grad/Mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Mul_grad/Mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Mul_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/Mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/policy_grad/mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/policy_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/policy_grad/sub: (Sub): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/policy_grad/mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/policy_fc/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/policy_fc/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/policy_fc/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/strided_slice_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/ppo_head_0/strided_slice_grad/StridedSliceGrad: (StridedSliceGrad): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/add_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/add_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/add_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/add_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/add_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/add_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/add_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_grad/Mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_grad/Mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_1_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_1_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_1_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_1_grad/Mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_1_grad/Sum: (Sum): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_1_grad/Mul_1: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_1_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_1_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/mul_1/y_grad/unstack: (Unpack): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/middleware_fc_embedder/BatchnormActivationDropout_1_activation_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/middleware_fc_embedder/Dense_0/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/middleware_fc_embedder/Dense_0/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/middleware_fc_embedder/Dense_0/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Flatten/flatten/Reshape_grad/Shape: (Shape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Flatten/flatten/Reshape_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/BatchnormActivationDropout_5_activation_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_4/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_4/Conv2D_grad/ShapeN: (ShapeN): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_4/Conv2D_grad/Conv2DBackpropInput: (Conv2DBackpropInput): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_4/Conv2D_grad/Conv2DBackpropFilter: (Conv2DBackpropFilter): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/BatchnormActivationDropout_3_activation_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_2/BiasAdd_grad/BiasAddGrad: (BiasAddGrad): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_2/Conv2D_grad/ShapeN: (ShapeN): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_2/Conv2D_grad/Conv2DBackpropInput: (Conv2DBackpropInput): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_2/Conv2D_grad/Conv2DBackpropFilter: (Conv2DBackpropFilter): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "gradients/main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/BatchnormActivationDropout_1_activation_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_0/FRONT_FACING_CAMERA/FRONT_FACING_CAMERA: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/truediv/y: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/sub/y: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_0/kernel: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_0/bias: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_2/kernel: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_2/bias: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_4/kernel: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "main_level/agent/main/online/network_1/FRONT_FACING_CAMERA/Conv2d_4/bias: (Const): /job:localhost/replica:0/task"
     ]
    }
   ],
   "source": [
    "reader = rosbag2_py.SequentialReader()\n",
    "reader.open(storage_options, converter_options)\n",
    "reader.set_filter(storage_filter)\n",
    "\n",
    "first_stamp = -1\n",
    "steps_data = {'steps': []}\n",
    "\n",
    "action_names = []\n",
    "with open(metadata_json,\"r\") as jsonin:\n",
    "    model_metadata=json.load(jsonin)\n",
    "for action in model_metadata['action_space']:\n",
    "    action_names.append(str(action['steering_angle'])+ u'\\N{DEGREE SIGN}' + \" \"+\"%.1f\"%action[\"speed\"])\n",
    "\n",
    "writer = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*CODEC), fps, (width, height))\n",
    "fig = create_plot(action_names, height, width, 72)\n",
    "\n",
    "p_bar = tqdm(total=s)\n",
    "\n",
    "s = 0\n",
    "with model.session as sess:\n",
    "\n",
    "    cam = GradCam(model, model.get_conv_outputs())\n",
    "\n",
    "    while reader.has_next():\n",
    "        step = {}\n",
    "        \n",
    "        (topic, data, t) = reader.read_next()\n",
    "        msg = deserialize_message(data, InferResultsArray)\n",
    "\n",
    "        # Timestamp\n",
    "        timestamp: float = (msg.images[0].header.stamp.sec + msg.images[0].header.stamp.nanosec / 1e9)\n",
    "\n",
    "        if first_stamp == -1:\n",
    "            first_stamp = timestamp\n",
    "            timestamp = 0\n",
    "        else:\n",
    "            timestamp = timestamp - first_stamp\n",
    "\n",
    "        step['timestamp'] = timestamp\n",
    "        step['seq'] = int(msg.images[0].header.frame_id)\n",
    "\n",
    "        # Extract original image from first camera\n",
    "        cv_img_bgra = bridge.compressed_imgmsg_to_cv2(msg.images[0], desired_encoding=\"passthrough\")\n",
    "        cv_img = cv2.cvtColor(cv_img_bgra, cv2.COLOR_BGRA2RGB)\n",
    "        # step['img'] = cv_img\n",
    "        \n",
    "        # Find best OpenVINO Result\n",
    "        step['openvino_action'] = {'action': -1, 'probability': -1}    \n",
    "        step['openvino_results'] = []\n",
    "        for r in msg.results:\n",
    "            step['openvino_results'].append({'action': r.class_label, 'probability': r.class_prob})\n",
    "            if r.class_prob > step['openvino_action']['probability']:\n",
    "                step['openvino_action'] = {'action': r.class_label, 'probability': r.class_prob}\n",
    "\n",
    "        # Process image with Tensorflow\n",
    "        tf_result, grad_img = cam.process(cv_img)\n",
    "        #step['gradcam_img'] = grad_img\n",
    "        \n",
    "        step['tf_action'] = {'action': -1, 'probability': -1}    \n",
    "        step['tf_results'] = []\n",
    "        for i, r in enumerate(tf_result):\n",
    "            step['tf_results'].append({'action': i, 'probability': r})\n",
    "            if r > step['tf_action']['probability']:\n",
    "                step['tf_action'] = {'action': i, 'probability': r}\n",
    "\n",
    "\n",
    "        # Edit image and process with Tensorflow\n",
    "        ed_img = cv2.cvtColor(cv_img_bgra, cv2.COLOR_RGB2RGBA)\n",
    "        ed_img = apply_gradient(ed_img, gradient_alpha_rgb_mul, one_minus_gradient_alpha)\n",
    "        ed_img = cv2.cvtColor(ed_img, cv2.COLOR_BGRA2RGB)\n",
    "        tf_result_2, grad_img_2 = cam.process(ed_img)\n",
    "        #step['gradcam_img'] = grad_img\n",
    "        \n",
    "        step['tf_action_2'] = {'action': -1, 'probability': -1}    \n",
    "        step['tf_results_2'] = []\n",
    "        for i, r in enumerate(tf_result_2):\n",
    "            step['tf_results_2'].append({'action': i, 'probability': r})\n",
    "            if r > step['tf_action_2']['probability']:\n",
    "                step['tf_action_2'] = {'action': i, 'probability': r}\n",
    "\n",
    "        # Results\n",
    "        step['results'] = []\n",
    "\n",
    "        # Plot image\n",
    "        img = update_plot(fig, step, action_names, cv_img, grad_img, grad_img_2)\n",
    "        \n",
    "        p_bar.update(1)\n",
    "\n",
    "        steps_data['steps'].append(step)\n",
    "\n",
    "        writer.write(img)\n",
    "\n",
    "\n",
    "writer.release()\n",
    "plt.close(fig)\n",
    "p_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(steps_data['steps'])\n",
    "del steps_data\n",
    "df['action_agree'] = np.where(df['openvino_action.action'] == df['tf_action.action'], 1, 0)\n",
    "df['action_diff'] = np.abs(df['openvino_action.action'] - df['tf_action.action'])\n",
    "action_analysis = df[['timestamp','seq','openvino_action.action','openvino_action.probability','tf_action.action', 'tf_action.probability', 'action_agree', 'action_diff']]\n",
    "action_analysis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histogram\n",
    "fig, ax = plt.subplots(1, 3, figsize =(20, 5), sharey=True)\n",
    "ax[0].hist(df['openvino_action.probability'], bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "ax[1].hist(df['tf_action.probability'], bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "ax[2].hist(df['tf_action_2.probability'], bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_a_c = pd.DataFrame(df['openvino_action.action'].value_counts(sort = False))\n",
    "tf_a_c = pd.DataFrame(df['tf_action.action'].value_counts(sort = False))\n",
    "a_c = ov_a_c.merge(tf_a_c, left_index=True, right_index=True).sort_index()\n",
    "a_c.index.name='action'\n",
    "a_c.rename(columns = {'tf_action.action':'tf', 'openvino_action.action': 'openvino'}, inplace = True)\n",
    "display(a_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize =(15, 5), sharey=True)\n",
    "fig.lab\n",
    "ax[0].bar(a_c.index,a_c['openvino'][::-1])\n",
    "plt.setp(ax[0], xlabel=\"OpenVINO\")\n",
    "plt.sca(ax[0])\n",
    "plt.xticks(a_c.index,action_names[::-1],rotation='vertical')\n",
    "\n",
    "ax[1].bar(a_c.index,a_c['tf'][::-1])\n",
    "plt.setp(ax[1], xlabel=\"Tensorflow\")\n",
    "plt.sca(ax[1])\n",
    "plt.xticks(a_c.index,action_names[::-1],rotation='vertical')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
